{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcbhavana27/ITS/blob/main/nas_Conv_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahF5toog4Fh1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from keras.models import Sequential,Model\n",
        "import tensorflow as tf\n",
        "from keras.metrics import MeanSquaredError as mae\n",
        "from keras import layers\n",
        "from keras.layers import LSTM,Dense,Dropout,Conv1D,TimeDistributed,Input,Flatten,RepeatVector,Bidirectional,Concatenate,SeparableConv1D,DepthwiseConv1D\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "#from bokeh.plotting import figure,output_file, show\n",
        "import datetime\n",
        "\n",
        "#from openpyxl import Workbook,load_workbook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQsb_kxp4Pby",
        "outputId": "10191c18-c274-41f1-f931-232dd9488ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  /content/drive/My\\ Drive/DATA.zip /content/\n",
        "!unzip DATA.zip"
      ],
      "metadata": {
        "id": "R78JTMum4ZQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OnuEOKj4Fh5"
      },
      "outputs": [],
      "source": [
        "Data_file1= glob('DATA/402214'+'/*.csv')\n",
        "Data_file2= glob('DATA/402510'+'/*.csv')\n",
        "Data_file3= glob('DATA/402835'+'/*.csv')\n",
        "Data_file4= glob('DATA/414025'+'/*.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kiw9J-A4Fh6"
      },
      "outputs": [],
      "source": [
        "def data(files,col):\n",
        "    data=[]\n",
        "    for file in files:\n",
        "          data.append(pd.read_csv(file))\n",
        "    full_data =pd.concat(data,ignore_index=True)\n",
        "    cols=list(full_data)[col]\n",
        "    data_set=full_data[cols].astype(str)\n",
        "    data_set = np.array(data_set)\n",
        "    print(len(files),len(data_set))\n",
        "    return data_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5mRWRnq4Fh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b8ac3d-319c-4333-b63c-fefbe689e4f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 26193\n",
            "13 26191\n",
            "13 26192\n",
            "13 26192\n"
          ]
        }
      ],
      "source": [
        "Data1 = data(Data_file1,2)\n",
        "Data2 = data(Data_file2,2)\n",
        "Data3 = data(Data_file3,2)\n",
        "Data4 = data(Data_file4,2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Data1[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcDmkcwWrONL",
        "outputId": "a95a9465-337b-4b46-d7ca-3a29ef529e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['36' '35' '33' '32' '30']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0w_0uck4Fh7",
        "outputId": "b45242bc-18c3-4287-92e9-3280fdff8cee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26193,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "Data1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h4v2ogI4Fh8"
      },
      "outputs": [],
      "source": [
        "data1 = Data1.reshape(Data1.shape[0],1)\n",
        "scaler1 =MinMaxScaler(feature_range=(0, 1))\n",
        "data1_scaled = scaler1.fit_transform(data1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TZ2j1sM5nhG",
        "outputId": "cd039715-6303-442b-d86d-617a20c89d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26193, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1a = np.array(data1)\n",
        "np.save('data1.npy',np.array(data1),allow_pickle=True)"
      ],
      "metadata": {
        "id": "2Fp-FEgh23hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4kHSINM4Fh9"
      },
      "outputs": [],
      "source": [
        "data_set = ([Data1,Data2,Data3,Data4])\n",
        "max_len =max([len(data) for data in data_set ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41WpZygS4Fh9"
      },
      "outputs": [],
      "source": [
        "def fill_data(data):\n",
        "    x=data\n",
        "    l=len(x)\n",
        "    y=x\n",
        "    while l<max_len:\n",
        "        y= np.insert(x,-1,x[-1])\n",
        "        x=y\n",
        "        l=len(x)\n",
        "    return y\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3reCTUwn4Fh-"
      },
      "outputs": [],
      "source": [
        "data1 = fill_data(Data1)\n",
        "data2 = fill_data(Data2)\n",
        "data3 = fill_data(Data3)\n",
        "data4 = fill_data(Data4)\n",
        "data_set = np.column_stack((data1,data2,data3,data4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpgJVPBo4Fh-"
      },
      "outputs": [],
      "source": [
        "scaler =MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Mf7VzfB4Fh-"
      },
      "outputs": [],
      "source": [
        "n_step = 15\n",
        "Data =[]\n",
        "\n",
        "for i in range(max_len-16):\n",
        "    Data.append(data_scaled[i:i+n_step+1])\n",
        "\n",
        "Data =np.array(Data)\n",
        "#Data = Data.reshape(Data.shape[0],Data.shape[2],Data.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbkMsUEj4Fh_",
        "outputId": "f53e7845-2083-4700-e72e-63e8f13a5a4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26177, 16, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "Data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RktyGAh74Fh_"
      },
      "outputs": [],
      "source": [
        "Train = Data[:]\n",
        "Train_Y=Train[:,-1,0]\n",
        "Train_X = Train[:,:15]\n",
        "Train_wd =Train[:,:15,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_WWp8DG4Fh_"
      },
      "outputs": [],
      "source": [
        "x=[]\n",
        "x_w=[]\n",
        "x_d=[]\n",
        "y=[]\n",
        "for i in range(len(Train)):\n",
        "    if i >= 2016:\n",
        "        x.append(Train_X[i])\n",
        "        x_w.append(Train_wd[i-2016])\n",
        "        x_d.append(Train_wd[i-288])\n",
        "        y.append(Train_Y[i])\n",
        "x=np.array(x)\n",
        "x_w=np.array(x_w)\n",
        "x_d=np.array(x_d)\n",
        "y=np.array(y)      \n",
        "y=y.reshape(y.shape[0],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8fN59Bz4FiA",
        "outputId": "978f59a3-5165-4939-9d31-588a8b135cbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24161, 15), (24161, 15))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x_d.shape,x_w.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgcFjxw54FiA",
        "outputId": "3b998654-c7eb-4a2c-846e-7ab8ab94b6f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08496732, 0.08496732, 0.07843137, ..., 0.22875817, 0.21568627,\n",
              "       0.20915033])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "Train_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD-RLXyK4FiA"
      },
      "outputs": [],
      "source": [
        "train_x=x[:-2016]\n",
        "test_x=x[-2016:]\n",
        "train_x_w=x_w[:-2016]\n",
        "test_x_w=x_w[-2016:]\n",
        "train_x_d=x_d[:-2016]\n",
        "test_x_d=x_d[-2016:]\n",
        "train_y=y[:-2016]\n",
        "test_y=y[-2016:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfmhx_5Q4FiB"
      },
      "outputs": [],
      "source": [
        "train_x =train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
        "test_x =test_x.reshape(test_x.shape[0],test_x.shape[1],test_x.shape[2],1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('test_x.npy',np.array(test_x),allow_pickle=True)\n",
        "np.save('test_x_w.npy',np.array(test_x_w),allow_pickle=True)\n",
        "np.save('test_x_d.npy',np.array(test_x_d),allow_pickle=True)\n",
        "np.save('test_y.npy',np.array(test_y),allow_pickle=True)"
      ],
      "metadata": {
        "id": "0j-9LoK7X7vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=np.load('test_x.npy',allow_pickle=True)"
      ],
      "metadata": {
        "id": "FeGXX6pDX78z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmRrstrn4FiB"
      },
      "outputs": [],
      "source": [
        "input1 = Input((n_step,4),name='input1')\n",
        "input2 = Input((n_step,1),name='input2')\n",
        "input3 = Input((n_step,1),name='input3')\n",
        "# con1=Conv1D(30,3,strides=1,activation='relu',name='con1')(input1)\n",
        "ds1=SeparableConv1D(30,3,strides=1,activation='relu',name='ds1')(input1)\n",
        "# ds1=DepthwiseConv1D(30,3,strides=1,activation='relu',name='ds1')(input1)\n",
        "\n",
        "# con2=Conv1D(20,3,strides=1,activation='relu',name='con2')(con1)\n",
        "ds2=SeparableConv1D(20,3,strides=1,activation='relu',name='ds2')(ds1)\n",
        "# ds2=DepthwiseConv1D(20,3,strides=1,activation='relu',name='ds2')(ds1)\n",
        "con_f=Flatten()(ds2)\n",
        "con_out=RepeatVector(1)(con_f)\n",
        "lstm_out=LSTM(50,activation =\"relu\",return_sequences=False,name='lstm_out')(con_out)\n",
        "Bilstm_out1=Bidirectional(LSTM(40,activation =\"relu\",return_sequences=False))(input2)\n",
        "Bilstm_out2=Bidirectional(LSTM(40,activation =\"relu\",return_sequences=False))(input3)\n",
        "x=Concatenate()([lstm_out,Bilstm_out1,Bilstm_out2])\n",
        "x1=Dense(20,activation='relu',name='x1')(x)\n",
        "x2=Dense(10,activation='relu',name='x2')(x1)\n",
        "output = Dense(1,activation='relu',name='output')(x2)\n",
        "model= Model(inputs=[input1,input2,input3],outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss = \"mse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2UmGWym4FiB",
        "outputId": "fdd6963d-9f95-4a08-a468-7f5940ebe76b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input1 (InputLayer)            [(None, 15, 4)]      0           []                               \n",
            "                                                                                                  \n",
            " ds1 (SeparableConv1D)          (None, 13, 30)       162         ['input1[0][0]']                 \n",
            "                                                                                                  \n",
            " ds2 (SeparableConv1D)          (None, 11, 20)       710         ['ds1[0][0]']                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 220)          0           ['ds2[0][0]']                    \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (None, 1, 220)       0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " input2 (InputLayer)            [(None, 15, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input3 (InputLayer)            [(None, 15, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_out (LSTM)                (None, 50)           54200       ['repeat_vector[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 80)           13440       ['input2[0][0]']                 \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 80)          13440       ['input3[0][0]']                 \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 210)          0           ['lstm_out[0][0]',               \n",
            "                                                                  'bidirectional[0][0]',          \n",
            "                                                                  'bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " x1 (Dense)                     (None, 20)           4220        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " x2 (Dense)                     (None, 10)           210         ['x1[0][0]']                     \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            11          ['x2[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 86,393\n",
            "Trainable params: 86,393\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrKOtM6R4FiB",
        "outputId": "4a7760c1-d2c0-4ab6-9bfb-caef988bfe7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "589/589 [==============================] - 83s 112ms/step - loss: 0.0084 - val_loss: 0.0011\n",
            "Epoch 2/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 5.5311e-04 - val_loss: 0.0011\n",
            "Epoch 3/50\n",
            "589/589 [==============================] - 64s 108ms/step - loss: 4.6925e-04 - val_loss: 8.3497e-04\n",
            "Epoch 4/50\n",
            "589/589 [==============================] - 66s 112ms/step - loss: 3.3265e-04 - val_loss: 6.9442e-04\n",
            "Epoch 5/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 2.9717e-04 - val_loss: 6.7423e-04\n",
            "Epoch 6/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 2.4073e-04 - val_loss: 6.7036e-04\n",
            "Epoch 7/50\n",
            "589/589 [==============================] - 63s 107ms/step - loss: 2.3661e-04 - val_loss: 6.3340e-04\n",
            "Epoch 8/50\n",
            "589/589 [==============================] - 65s 110ms/step - loss: 2.2655e-04 - val_loss: 6.4075e-04\n",
            "Epoch 9/50\n",
            "589/589 [==============================] - 64s 108ms/step - loss: 2.1021e-04 - val_loss: 6.0823e-04\n",
            "Epoch 10/50\n",
            "589/589 [==============================] - 64s 108ms/step - loss: 2.0658e-04 - val_loss: 9.2781e-04\n",
            "Epoch 11/50\n",
            "589/589 [==============================] - 62s 105ms/step - loss: 2.1849e-04 - val_loss: 6.2493e-04\n",
            "Epoch 12/50\n",
            "589/589 [==============================] - 65s 110ms/step - loss: 1.9684e-04 - val_loss: 5.1155e-04\n",
            "Epoch 13/50\n",
            "589/589 [==============================] - 63s 108ms/step - loss: 1.8186e-04 - val_loss: 5.0208e-04\n",
            "Epoch 14/50\n",
            "589/589 [==============================] - 63s 107ms/step - loss: 1.8437e-04 - val_loss: 5.3721e-04\n",
            "Epoch 15/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.7789e-04 - val_loss: 5.6998e-04\n",
            "Epoch 16/50\n",
            "589/589 [==============================] - 65s 111ms/step - loss: 1.8508e-04 - val_loss: 5.4254e-04\n",
            "Epoch 17/50\n",
            "589/589 [==============================] - 64s 108ms/step - loss: 1.7456e-04 - val_loss: 5.0925e-04\n",
            "Epoch 18/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.7200e-04 - val_loss: 7.8055e-04\n",
            "Epoch 19/50\n",
            "589/589 [==============================] - 63s 107ms/step - loss: 1.8391e-04 - val_loss: 3.6473e-04\n",
            "Epoch 20/50\n",
            "589/589 [==============================] - 66s 112ms/step - loss: 1.6803e-04 - val_loss: 3.2984e-04\n",
            "Epoch 21/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.6003e-04 - val_loss: 3.3582e-04\n",
            "Epoch 22/50\n",
            "589/589 [==============================] - 64s 108ms/step - loss: 1.5048e-04 - val_loss: 2.6772e-04\n",
            "Epoch 23/50\n",
            "589/589 [==============================] - 63s 107ms/step - loss: 1.6119e-04 - val_loss: 2.9242e-04\n",
            "Epoch 24/50\n",
            "589/589 [==============================] - 66s 111ms/step - loss: 1.4489e-04 - val_loss: 2.2926e-04\n",
            "Epoch 25/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.4047e-04 - val_loss: 2.5988e-04\n",
            "Epoch 26/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.3768e-04 - val_loss: 2.1447e-04\n",
            "Epoch 27/50\n",
            "589/589 [==============================] - 63s 107ms/step - loss: 1.4098e-04 - val_loss: 2.5544e-04\n",
            "Epoch 28/50\n",
            "589/589 [==============================] - 65s 110ms/step - loss: 1.5220e-04 - val_loss: 1.7065e-04\n",
            "Epoch 29/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.3070e-04 - val_loss: 2.1199e-04\n",
            "Epoch 30/50\n",
            "589/589 [==============================] - 64s 108ms/step - loss: 1.3627e-04 - val_loss: 3.5802e-04\n",
            "Epoch 31/50\n",
            "589/589 [==============================] - 64s 108ms/step - loss: 1.3744e-04 - val_loss: 2.0975e-04\n",
            "Epoch 32/50\n",
            "589/589 [==============================] - 66s 112ms/step - loss: 1.2936e-04 - val_loss: 1.7424e-04\n",
            "Epoch 33/50\n",
            "589/589 [==============================] - 65s 110ms/step - loss: 1.3336e-04 - val_loss: 1.2870e-04\n",
            "Epoch 34/50\n",
            "589/589 [==============================] - 65s 110ms/step - loss: 1.2309e-04 - val_loss: 2.2007e-04\n",
            "Epoch 35/50\n",
            "589/589 [==============================] - 66s 111ms/step - loss: 1.5032e-04 - val_loss: 1.2445e-04\n",
            "Epoch 36/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.3315e-04 - val_loss: 1.3049e-04\n",
            "Epoch 37/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.2167e-04 - val_loss: 1.2816e-04\n",
            "Epoch 38/50\n",
            "589/589 [==============================] - 63s 107ms/step - loss: 1.2651e-04 - val_loss: 1.4051e-04\n",
            "Epoch 39/50\n",
            "589/589 [==============================] - 66s 112ms/step - loss: 1.2932e-04 - val_loss: 1.0480e-04\n",
            "Epoch 40/50\n",
            "589/589 [==============================] - 66s 112ms/step - loss: 1.1729e-04 - val_loss: 8.7638e-05\n",
            "Epoch 41/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.1657e-04 - val_loss: 8.8722e-05\n",
            "Epoch 42/50\n",
            "589/589 [==============================] - 63s 107ms/step - loss: 1.1316e-04 - val_loss: 1.8375e-04\n",
            "Epoch 43/50\n",
            "589/589 [==============================] - 65s 110ms/step - loss: 1.1819e-04 - val_loss: 6.7352e-05\n",
            "Epoch 44/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.1454e-04 - val_loss: 6.2611e-05\n",
            "Epoch 45/50\n",
            "589/589 [==============================] - 64s 108ms/step - loss: 1.2111e-04 - val_loss: 1.2620e-04\n",
            "Epoch 46/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.1755e-04 - val_loss: 2.3232e-04\n",
            "Epoch 47/50\n",
            "589/589 [==============================] - 65s 111ms/step - loss: 1.1764e-04 - val_loss: 5.9303e-05\n",
            "Epoch 48/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.1156e-04 - val_loss: 6.2698e-05\n",
            "Epoch 49/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.0752e-04 - val_loss: 7.2844e-05\n",
            "Epoch 50/50\n",
            "589/589 [==============================] - 64s 109ms/step - loss: 1.1429e-04 - val_loss: 1.5775e-04\n"
          ]
        }
      ],
      "source": [
        "history=model.fit([train_x,train_x_w,train_x_d],train_y,epochs=50,validation_split=.15, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"depsepconvlstmmodel.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"conv_lstm_sep.h5\")"
      ],
      "metadata": {
        "id": "yL373UrD-tDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v674DZtY4FiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c6cf30dd-fc22-4fce-b71b-2cf41f7937b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history[\"loss\"],color='green')\n",
        "plt.plot(history.history[\"val_loss\"],color='blue')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "js = open(\"/content/depsepconvlstmmodel.json\")\n",
        "lm = js.read()\n",
        "js.close()\n",
        "model1 = tf.keras.models.model_from_json(lm)"
      ],
      "metadata": {
        "id": "N3iJBxI1mVey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=model1\n",
        "\n",
        "new_model.load_weights(\"conv_lstm_sep.h5\")"
      ],
      "metadata": {
        "id": "agaoZI0QQpIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb4LjxYA4FiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53d0c4f-e046-4433-f363-ed1598f3a169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "y_predict_scaled =new_model.predict([test_x,test_x_w,test_x_d])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6n4YoO94FiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ebc6aa-a9a3-44e9-e64a-611444f8f5c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2016, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "y_predict_scaled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuqcIe7r4FiC"
      },
      "outputs": [],
      "source": [
        "y_predict=scaler1.inverse_transform(y_predict_scaled )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksqH4xg24FiD"
      },
      "outputs": [],
      "source": [
        "test_Y=scaler1.inverse_transform(test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjdN54zy4FiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecf84db-4c2e-4a90-b83e-dd3f3c758f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2195696863863208\n"
          ]
        }
      ],
      "source": [
        "print(mae(y_predict,test_Y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkIYb4LT4FiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070ddc78-a943-48a6-c0ba-a1ade8c7d337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.529896227102754\n"
          ]
        }
      ],
      "source": [
        "print(sqrt(mse(y_predict,test_Y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tp8vBt54FiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db10f413-0803-47d2-a223-b8641a362799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.021938841278372433\n"
          ]
        }
      ],
      "source": [
        "print(mape(y_predict,test_Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NAS "
      ],
      "metadata": {
        "id": "soJBvLkSv6d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_mac_ops(model):\n",
        "    total_mac_ops = 0\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, layers.Conv1D):\n",
        "            mac_ops = layer.kernel_size[0] * layer.output_shape[1] * layer.filters * layer.input_shape[-1]\n",
        "        elif isinstance(layer, layers.SeparableConv1D):\n",
        "            mac_ops = layer.kernel_size[0] * layer.output_shape[1] * layer.depth_multiplier * layer.input_shape[-1] + layer.output_shape[1] * layer.filters\n",
        "        elif isinstance(layer, layers.Conv2D):\n",
        "            mac_ops = layer.kernel_size[0] * layer.kernel_size[1] * layer.output_shape[1] * layer.output_shape[2] * layer.filters * layer.input_shape[-1]\n",
        "        elif isinstance(layer, layers.SeparableConv2D):\n",
        "            mac_ops = (layer.kernel_size[0] * layer.kernel_size[1] * layer.input_shape[-1] * layer.depth_multiplier +\n",
        "                      layer.output_shape[1] * layer.output_shape[2] * layer.filters)\n",
        "        elif isinstance(layer, layers.Dense):\n",
        "            mac_ops = layer.input_shape[-1] * layer.output_shape[-1]\n",
        "        elif isinstance(layer, layers.LSTM) or isinstance(layer, layers.GRU):\n",
        "            mac_ops = 4 * (layer.input_shape[-1] * layer.units + layer.units**2)\n",
        "        elif isinstance(layer, layers.Bidirectional):\n",
        "            forward_layer = layer.forward_layer\n",
        "            backward_layer = layer.backward_layer\n",
        "            forward_mac_ops = 4 * (layer.input_shape[-1] * forward_layer.units + forward_layer.units**2)\n",
        "            backward_mac_ops = 4 * (layer.input_shape[-1] * backward_layer.units + backward_layer.units**2)\n",
        "            mac_ops = 2 * (forward_mac_ops + backward_mac_ops)\n",
        "        else:\n",
        "            mac_ops = 0\n",
        "        total_mac_ops += mac_ops\n",
        "    return total_mac_ops\n"
      ],
      "metadata": {
        "id": "oOrLhOGGv4ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_mac_ops(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF2yb55wBmyY",
        "outputId": "44677213-0638-4ed4-d212-3aff42fc25b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112646"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = Input((n_step,4),name='input1')\n",
        "input2 = Input((n_step,1),name='input2')\n",
        "input3 = Input((n_step,1),name='input3')\n",
        "con1=Conv1D(30,3,strides=1,activation='relu',name='con1')(input1)\n",
        "# ds1=SeparableConv1D(30,3,strides=1,activation='relu',name='ds1')(input1)\n",
        "# ds1=DepthwiseConv1D(30,3,strides=1,activation='relu',name='ds1')(input1)\n",
        "con2=Conv1D(20,3,strides=1,activation='relu',name='con2')(con1)\n",
        "# ds2=SeparableConv1D(20,3,strides=1,activation='relu',name='ds2')(ds1)\n",
        "# ds2=DepthwiseConv1D(20,3,strides=1,activation='relu',name='ds2')(ds1)\n",
        "con_f=Flatten()(con2)\n",
        "con_out=RepeatVector(1)(con_f)\n",
        "lstm_out=LSTM(50,activation =\"relu\",return_sequences=False,name='lstm_out')(con_out)\n",
        "Bilstm_out1=Bidirectional(LSTM(40,activation =\"relu\",return_sequences=False))(input2)\n",
        "Bilstm_out2=Bidirectional(LSTM(40,activation =\"relu\",return_sequences=False))(input3)\n",
        "x=Concatenate()([lstm_out,Bilstm_out1,Bilstm_out2])\n",
        "x1=Dense(20,activation='relu',name='x1')(x)\n",
        "x2=Dense(10,activation='relu',name='x2')(x1)\n",
        "output = Dense(1,activation='relu',name='output')(x2)\n",
        "model2= Model(inputs=[input1,input2,input3],outputs=output)\n",
        "model2.compile(optimizer=\"adam\", loss = \"mse\")"
      ],
      "metadata": {
        "id": "pJ6wD2TRv5Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_mac_ops(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5O7KbPIv5EM",
        "outputId": "16534faa-9949-4d41-8ad0-919df27bc81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135370"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "lHG3X61UOkEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nas approach"
      ],
      "metadata": {
        "id": "yLjWNCBqIVEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "width_multipliers = [0.2, 0.4, 0.7, 0.8, 0.9, 1.0]\n",
        "min_depth = 3\n",
        "max_depth = 9\n",
        "threshold_mac_ops = 70000  # threshold for the maximum number of MAC operations\n",
        "target_loss = 0.04 # target validation loss for stopping the model training\n",
        "fail_loss = 0.04 # validation loss for discarding the model"
      ],
      "metadata": {
        "id": "s5WMqqmOv2Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feasible_models =[]\n",
        "for width in width_multipliers:\n",
        "  for depth in range(3,8):\n",
        "    input1 = Input((n_step,4),name='input1')\n",
        "    input2 = Input((n_step,1),name='input2')\n",
        "    input3 = Input((n_step,1),name='input3')\n",
        "    x = SeparableConv1D(int(30 * width), 3, strides=1, activation='relu')(input1)\n",
        "    for i in range(depth - 1):\n",
        "        x = SeparableConv1D(int(20 * width), 3, strides=1, activation='relu')(x)\n",
        "    con_f = Flatten()(x)\n",
        "    con_out = RepeatVector(1)(con_f)\n",
        "    lstm_out = LSTM(int(50 * width), activation='relu', return_sequences=False)(con_out)\n",
        "    Bilstm_out1 = Bidirectional(LSTM(int(40 * width), activation='relu', return_sequences=False))(input2)\n",
        "    Bilstm_out2 = Bidirectional(LSTM(int(40 * width), activation='relu', return_sequences=False))(input3)\n",
        "    x = Concatenate()([lstm_out, Bilstm_out1, Bilstm_out2])\n",
        "    x = Dense(int(20 * width), activation='relu')(x)\n",
        "    x = Dense(int(10 * width), activation='relu')(x)\n",
        "    output = Dense(1, activation='relu')(x)\n",
        "    modeln = Model(inputs=[input1,input2,input3],outputs=output)\n",
        "    modeln.compile(optimizer=\"adam\", loss = \"mse\")\n",
        "    maco = count_mac_ops(modeln)\n",
        "    print(maco)\n",
        "    if(maco < threshold_mac_ops):\n",
        "      feasible_models.append(modeln)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VEch83Mv2cO",
        "outputId": "49500c0b-50a6-4c7f-b1ec-52d7127b29dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4942\n",
            "4734\n",
            "4494\n",
            "4222\n",
            "3918\n",
            "17856\n",
            "16800\n",
            "15680\n",
            "14496\n",
            "13248\n",
            "52467\n",
            "48939\n",
            "45299\n",
            "41547\n",
            "37683\n",
            "68068\n",
            "63396\n",
            "58596\n",
            "53668\n",
            "48612\n",
            "85701\n",
            "79725\n",
            "73605\n",
            "67341\n",
            "60933\n",
            "105366\n",
            "97926\n",
            "90326\n",
            "82566\n",
            "74646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(feasible_models))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv51bpHoz64E",
        "outputId": "70736721-187e-40f2-cf33-31c851ddb39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models=[]\n",
        "for modeli in feasible_models:\n",
        "  historyi = modeli.fit([train_x,train_x_w,train_x_d],train_y,epochs=3,validation_split=.15, verbose=1)\n",
        "  yps = modeli.predict([test_x,test_x_w,test_x_d])\n",
        "  yp=scaler1.inverse_transform(yps )\n",
        "  maee = mae(yp,test_Y)\n",
        "  msee=sqrt(mse(yp,test_Y))\n",
        "  mapee=mape(yp,test_Y)\n",
        "  print(\"mae\",maee)\n",
        "  print(\"mse\",msee)\n",
        "  print(\"mape\",mapee)\n",
        "  print(\"\\n\")\n",
        "  if(maee <3.5 and msee<4 and mapee<0.05):\n",
        "    best_models.append(modeli)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1Ggrsg0v2fM",
        "outputId": "e1333c29-ef19-4068-8c27-e12c72513224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 7.1799e-04 - val_loss: 3.8742e-04\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 18s 30ms/step - loss: 6.7876e-04 - val_loss: 8.6519e-04\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 6.7494e-04 - val_loss: 5.3242e-04\n",
            "63/63 [==============================] - 1s 12ms/step\n",
            "mae 2.718329146740929\n",
            "mse 3.5490449783418403\n",
            "mape 0.0516469176569066\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 17s 29ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 19s 31ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 10ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 9.0630e-04 - val_loss: 0.0010\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 18s 31ms/step - loss: 8.2753e-04 - val_loss: 6.4832e-04\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 18s 31ms/step - loss: 8.0713e-04 - val_loss: 0.0011\n",
            "63/63 [==============================] - 1s 12ms/step\n",
            "mae 3.840338584213031\n",
            "mse 4.904319206030481\n",
            "mape 0.0731166866898377\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 18s 31ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 13ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 0.0106 - val_loss: 0.0052\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 0.0103 - val_loss: 0.0046\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 0.0098 - val_loss: 0.0035\n",
            "63/63 [==============================] - 1s 12ms/step\n",
            "mae 5.8224672012858925\n",
            "mse 8.995828501766075\n",
            "mape 0.10093734805000754\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 13ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 7.5643e-04 - val_loss: 5.7309e-04\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 7.3346e-04 - val_loss: 3.8393e-04\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 6.9479e-04 - val_loss: 3.7269e-04\n",
            "63/63 [==============================] - 1s 9ms/step\n",
            "mae 2.1901746940991234\n",
            "mse 2.926552515708916\n",
            "mape 0.038574620390995525\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 8.9932e-04 - val_loss: 7.2616e-04\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 8.9765e-04 - val_loss: 7.6737e-04\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 20s 33ms/step - loss: 8.2990e-04 - val_loss: 6.4186e-04\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "mae 2.943327732502468\n",
            "mse 3.860498384993749\n",
            "mape 0.050684211276488964\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 0.0101 - val_loss: 0.0051\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 0.0097 - val_loss: 0.0042\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 0.0092 - val_loss: 0.0042\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "mae 6.690096799816404\n",
            "mse 9.668777258074984\n",
            "mape 0.10783128624258073\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 0.0113 - val_loss: 0.0061\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 0.0111 - val_loss: 0.0052\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 0.0110 - val_loss: 0.0050\n",
            "63/63 [==============================] - 0s 7ms/step\n",
            "mae 6.716652602430374\n",
            "mse 10.890086218731296\n",
            "mape 0.1082232964433499\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 6.7495e-04 - val_loss: 3.4707e-04\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 6.0036e-04 - val_loss: 5.5234e-04\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 5.6998e-04 - val_loss: 3.9145e-04\n",
            "63/63 [==============================] - 0s 7ms/step\n",
            "mae 2.229507603342571\n",
            "mse 3.0125342336269503\n",
            "mape 0.03634344801827059\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 7.0187e-04 - val_loss: 4.5402e-04\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 6.5385e-04 - val_loss: 3.5183e-04\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 5.8003e-04 - val_loss: 3.5905e-04\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "mae 2.125534347598515\n",
            "mse 2.8603266012614754\n",
            "mape 0.033481228280179576\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 7.2766e-04 - val_loss: 8.1733e-04\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 23s 38ms/step - loss: 6.4901e-04 - val_loss: 4.4876e-04\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 6.2334e-04 - val_loss: 5.2937e-04\n",
            "63/63 [==============================] - 1s 10ms/step\n",
            "mae 2.691156759148553\n",
            "mse 3.4964098471001965\n",
            "mape 0.05056217461859164\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 5.3142e-04 - val_loss: 3.4819e-04\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 4.7279e-04 - val_loss: 2.9876e-04\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 4.0210e-04 - val_loss: 2.6816e-04\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "mae 1.9556724190238928\n",
            "mse 2.45870371747369\n",
            "mape 0.04075636952071711\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 12ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 15ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 7.5041e-04 - val_loss: 8.8852e-04\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 6.9410e-04 - val_loss: 0.0011\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 6.4467e-04 - val_loss: 6.1894e-04\n",
            "63/63 [==============================] - 1s 13ms/step\n",
            "mae 2.866313236100333\n",
            "mse 3.72281950747395\n",
            "mape 0.0413456581347877\n",
            "\n",
            "\n",
            "Epoch 1/3\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 2/3\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "Epoch 3/3\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 0.3760 - val_loss: 0.4217\n",
            "63/63 [==============================] - 1s 9ms/step\n",
            "mae 86.0639880952381\n",
            "mse 98.52224841394802\n",
            "mape 3.875977447157331e+17\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(best_models))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oakA8YLfv2iC",
        "outputId": "56c55ae6-b534-4ec9-b331-9c46b3a9a9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "for modeli in best_models:\n",
        "  historyi = modeli.fit([train_x,train_x_w,train_x_d],train_y,epochs=50,validation_split=.15, verbose=1)\n",
        "  yps = modeli.predict([test_x,test_x_w,test_x_d])\n",
        "  yp=scaler1.inverse_transform(yps )\n",
        "  maee = mae(yp,test_Y)\n",
        "  msee=sqrt(mse(yp,test_Y))\n",
        "  mapee=mape(yp,test_Y)\n",
        "  print(\"model :\" ,c)\n",
        "  print(\"mae\",maee)\n",
        "  print(\"mse\",msee)\n",
        "  print(\"mape\",mapee)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model_json = modeli.to_json()\n",
        "  with open(\"depsepconvlstmmodel-\"+str(c)+\".json\", \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "  model.save_weights(\"conv_lstm_sep-\"+str(c)+\".h5\")\n",
        "\n",
        "  c+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-ia621wv2kd",
        "outputId": "b6a30a7c-bd73-4ce2-bd4e-2d4678e7a8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 1.2246e-04 - val_loss: 6.2934e-05\n",
            "Epoch 2/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.1750e-04 - val_loss: 1.0383e-04\n",
            "Epoch 3/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.2390e-04 - val_loss: 5.5283e-05\n",
            "Epoch 4/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.2419e-04 - val_loss: 7.4639e-05\n",
            "Epoch 5/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.1461e-04 - val_loss: 4.8604e-05\n",
            "Epoch 6/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.1888e-04 - val_loss: 6.3514e-05\n",
            "Epoch 7/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.1268e-04 - val_loss: 6.6304e-05\n",
            "Epoch 8/50\n",
            "589/589 [==============================] - 20s 33ms/step - loss: 1.1210e-04 - val_loss: 5.0974e-05\n",
            "Epoch 9/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.1722e-04 - val_loss: 5.8904e-05\n",
            "Epoch 10/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.1588e-04 - val_loss: 9.6294e-05\n",
            "Epoch 11/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.1513e-04 - val_loss: 1.0603e-04\n",
            "Epoch 12/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.1339e-04 - val_loss: 7.8943e-05\n",
            "Epoch 13/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.0988e-04 - val_loss: 7.1569e-05\n",
            "Epoch 14/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.1783e-04 - val_loss: 7.8229e-05\n",
            "Epoch 15/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.0641e-04 - val_loss: 5.7568e-05\n",
            "Epoch 16/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.1281e-04 - val_loss: 7.3739e-05\n",
            "Epoch 17/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.0692e-04 - val_loss: 9.4231e-05\n",
            "Epoch 18/50\n",
            "589/589 [==============================] - 20s 33ms/step - loss: 1.2053e-04 - val_loss: 4.5578e-05\n",
            "Epoch 19/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.0999e-04 - val_loss: 4.6434e-05\n",
            "Epoch 20/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.1478e-04 - val_loss: 1.3163e-04\n",
            "Epoch 21/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.1243e-04 - val_loss: 4.5835e-05\n",
            "Epoch 22/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.1234e-04 - val_loss: 5.2876e-05\n",
            "Epoch 23/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.1021e-04 - val_loss: 4.6756e-05\n",
            "Epoch 24/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.0970e-04 - val_loss: 1.3794e-04\n",
            "Epoch 25/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.0936e-04 - val_loss: 4.7389e-05\n",
            "Epoch 26/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.1423e-04 - val_loss: 4.8433e-05\n",
            "Epoch 27/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.1176e-04 - val_loss: 5.4126e-05\n",
            "Epoch 28/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.1337e-04 - val_loss: 1.0586e-04\n",
            "Epoch 29/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.0379e-04 - val_loss: 6.7307e-05\n",
            "Epoch 30/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.1179e-04 - val_loss: 4.7367e-05\n",
            "Epoch 31/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.0386e-04 - val_loss: 6.7118e-05\n",
            "Epoch 32/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.0998e-04 - val_loss: 6.0993e-05\n",
            "Epoch 33/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.0423e-04 - val_loss: 4.8207e-05\n",
            "Epoch 34/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.0725e-04 - val_loss: 5.9952e-05\n",
            "Epoch 35/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.1112e-04 - val_loss: 7.8203e-05\n",
            "Epoch 36/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.1009e-04 - val_loss: 4.7070e-05\n",
            "Epoch 37/50\n",
            "589/589 [==============================] - 20s 33ms/step - loss: 1.0245e-04 - val_loss: 4.8492e-05\n",
            "Epoch 38/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.0504e-04 - val_loss: 5.3976e-05\n",
            "Epoch 39/50\n",
            "589/589 [==============================] - 19s 32ms/step - loss: 1.0337e-04 - val_loss: 6.3427e-05\n",
            "Epoch 40/50\n",
            "589/589 [==============================] - 20s 33ms/step - loss: 1.1030e-04 - val_loss: 4.4128e-05\n",
            "Epoch 41/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.1103e-04 - val_loss: 6.6250e-05\n",
            "Epoch 42/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.0501e-04 - val_loss: 5.2457e-05\n",
            "Epoch 43/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.0765e-04 - val_loss: 4.7689e-05\n",
            "Epoch 44/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.0645e-04 - val_loss: 4.5934e-05\n",
            "Epoch 45/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.0816e-04 - val_loss: 4.5953e-05\n",
            "Epoch 46/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.0836e-04 - val_loss: 4.4404e-05\n",
            "Epoch 47/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.0814e-04 - val_loss: 5.1597e-05\n",
            "Epoch 48/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.0654e-04 - val_loss: 5.4402e-05\n",
            "Epoch 49/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.0194e-04 - val_loss: 4.9591e-05\n",
            "Epoch 50/50\n",
            "589/589 [==============================] - 19s 33ms/step - loss: 1.1340e-04 - val_loss: 9.8122e-05\n",
            "63/63 [==============================] - 0s 6ms/step\n",
            "model : 0\n",
            "mae 1.178879781847908\n",
            "mse 1.4829644867009713\n",
            "mape 0.020081711278341154\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 5.7329e-04 - val_loss: 3.6664e-04\n",
            "Epoch 2/50\n",
            "589/589 [==============================] - 23s 38ms/step - loss: 4.8392e-04 - val_loss: 4.5999e-04\n",
            "Epoch 3/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 4.8353e-04 - val_loss: 3.5996e-04\n",
            "Epoch 4/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 4.8742e-04 - val_loss: 5.2237e-04\n",
            "Epoch 5/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 4.2305e-04 - val_loss: 2.5188e-04\n",
            "Epoch 6/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 4.0801e-04 - val_loss: 1.6611e-04\n",
            "Epoch 7/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.6844e-04 - val_loss: 1.6763e-04\n",
            "Epoch 8/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 3.4336e-04 - val_loss: 1.6161e-04\n",
            "Epoch 9/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 3.1042e-04 - val_loss: 3.1766e-04\n",
            "Epoch 10/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 3.1178e-04 - val_loss: 1.2093e-04\n",
            "Epoch 11/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 2.7513e-04 - val_loss: 1.0329e-04\n",
            "Epoch 12/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.7563e-04 - val_loss: 2.0427e-04\n",
            "Epoch 13/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 2.6648e-04 - val_loss: 1.1378e-04\n",
            "Epoch 14/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 2.6908e-04 - val_loss: 9.6899e-05\n",
            "Epoch 15/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 2.5511e-04 - val_loss: 1.5406e-04\n",
            "Epoch 16/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.3080e-04 - val_loss: 1.3817e-04\n",
            "Epoch 17/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.9863e-04 - val_loss: 1.4291e-04\n",
            "Epoch 18/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 2.2904e-04 - val_loss: 6.8716e-05\n",
            "Epoch 19/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.8520e-04 - val_loss: 7.2457e-05\n",
            "Epoch 20/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.7223e-04 - val_loss: 2.1527e-04\n",
            "Epoch 21/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.6713e-04 - val_loss: 6.6245e-05\n",
            "Epoch 22/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.6392e-04 - val_loss: 1.4107e-04\n",
            "Epoch 23/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.5445e-04 - val_loss: 6.1431e-05\n",
            "Epoch 24/50\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 1.7665e-04 - val_loss: 5.9116e-04\n",
            "Epoch 25/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.5525e-04 - val_loss: 1.0937e-04\n",
            "Epoch 26/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.4840e-04 - val_loss: 6.5341e-05\n",
            "Epoch 27/50\n",
            "589/589 [==============================] - 20s 33ms/step - loss: 1.4829e-04 - val_loss: 8.9849e-05\n",
            "Epoch 28/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.5541e-04 - val_loss: 1.6597e-04\n",
            "Epoch 29/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.5130e-04 - val_loss: 1.1041e-04\n",
            "Epoch 30/50\n",
            "589/589 [==============================] - 20s 33ms/step - loss: 1.3525e-04 - val_loss: 1.4842e-04\n",
            "Epoch 31/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.4675e-04 - val_loss: 1.8840e-04\n",
            "Epoch 32/50\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 1.3467e-04 - val_loss: 5.7061e-05\n",
            "Epoch 33/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.4192e-04 - val_loss: 5.2214e-05\n",
            "Epoch 34/50\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 1.4333e-04 - val_loss: 1.0990e-04\n",
            "Epoch 35/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.3295e-04 - val_loss: 5.8527e-05\n",
            "Epoch 36/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.2657e-04 - val_loss: 5.9876e-04\n",
            "Epoch 37/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.4208e-04 - val_loss: 5.5243e-05\n",
            "Epoch 38/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.3374e-04 - val_loss: 7.5328e-05\n",
            "Epoch 39/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.2561e-04 - val_loss: 7.0954e-05\n",
            "Epoch 40/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.2695e-04 - val_loss: 8.4007e-05\n",
            "Epoch 41/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.2468e-04 - val_loss: 4.7852e-05\n",
            "Epoch 42/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.2219e-04 - val_loss: 4.8913e-05\n",
            "Epoch 43/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.3634e-04 - val_loss: 5.4988e-05\n",
            "Epoch 44/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.3476e-04 - val_loss: 7.3046e-05\n",
            "Epoch 45/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.3007e-04 - val_loss: 5.3244e-05\n",
            "Epoch 46/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.1373e-04 - val_loss: 4.5464e-05\n",
            "Epoch 47/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.1071e-04 - val_loss: 4.7718e-05\n",
            "Epoch 48/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.2557e-04 - val_loss: 1.4451e-04\n",
            "Epoch 49/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.1886e-04 - val_loss: 5.0000e-04\n",
            "Epoch 50/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.3409e-04 - val_loss: 4.6402e-05\n",
            "63/63 [==============================] - 1s 14ms/step\n",
            "model : 1\n",
            "mae 0.7788398563861849\n",
            "mse 1.0234463203982023\n",
            "mape 0.017086112517337756\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 5.9457e-04 - val_loss: 2.9583e-04\n",
            "Epoch 2/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 5.7600e-04 - val_loss: 9.1374e-04\n",
            "Epoch 3/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 5.0029e-04 - val_loss: 2.8507e-04\n",
            "Epoch 4/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 4.8877e-04 - val_loss: 5.4482e-04\n",
            "Epoch 5/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 5.1100e-04 - val_loss: 3.4521e-04\n",
            "Epoch 6/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 4.4780e-04 - val_loss: 2.7073e-04\n",
            "Epoch 7/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 4.4053e-04 - val_loss: 1.9965e-04\n",
            "Epoch 8/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 4.1917e-04 - val_loss: 2.4081e-04\n",
            "Epoch 9/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 3.7454e-04 - val_loss: 1.8637e-04\n",
            "Epoch 10/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 3.4862e-04 - val_loss: 1.9628e-04\n",
            "Epoch 11/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 3.5943e-04 - val_loss: 1.3944e-04\n",
            "Epoch 12/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 3.2902e-04 - val_loss: 1.1509e-04\n",
            "Epoch 13/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 2.9778e-04 - val_loss: 1.2035e-04\n",
            "Epoch 14/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.8636e-04 - val_loss: 1.8412e-04\n",
            "Epoch 15/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 2.8647e-04 - val_loss: 9.7989e-05\n",
            "Epoch 16/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.7721e-04 - val_loss: 1.4517e-04\n",
            "Epoch 17/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 2.9450e-04 - val_loss: 1.5938e-04\n",
            "Epoch 18/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.6667e-04 - val_loss: 8.1415e-05\n",
            "Epoch 19/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 2.6093e-04 - val_loss: 8.1317e-05\n",
            "Epoch 20/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.4749e-04 - val_loss: 8.6604e-05\n",
            "Epoch 21/50\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 2.2961e-04 - val_loss: 3.8585e-04\n",
            "Epoch 22/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.3399e-04 - val_loss: 4.9936e-04\n",
            "Epoch 23/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 2.1789e-04 - val_loss: 2.0451e-04\n",
            "Epoch 24/50\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 2.0751e-04 - val_loss: 8.7639e-05\n",
            "Epoch 25/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.8224e-04 - val_loss: 8.2582e-05\n",
            "Epoch 26/50\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 1.7289e-04 - val_loss: 8.4512e-05\n",
            "Epoch 27/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.7747e-04 - val_loss: 8.7268e-05\n",
            "Epoch 28/50\n",
            "589/589 [==============================] - 20s 35ms/step - loss: 1.7062e-04 - val_loss: 2.2691e-04\n",
            "Epoch 29/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.7060e-04 - val_loss: 5.9559e-05\n",
            "Epoch 30/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.6083e-04 - val_loss: 5.1999e-05\n",
            "Epoch 31/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.5465e-04 - val_loss: 1.1088e-04\n",
            "Epoch 32/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.7261e-04 - val_loss: 9.1901e-05\n",
            "Epoch 33/50\n",
            "589/589 [==============================] - 20s 34ms/step - loss: 1.5037e-04 - val_loss: 7.0389e-05\n",
            "Epoch 34/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.5851e-04 - val_loss: 9.4112e-05\n",
            "Epoch 35/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.5359e-04 - val_loss: 6.5205e-05\n",
            "Epoch 36/50\n",
            "589/589 [==============================] - 23s 38ms/step - loss: 1.4765e-04 - val_loss: 1.5065e-04\n",
            "Epoch 37/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.5985e-04 - val_loss: 5.0488e-05\n",
            "Epoch 38/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.3801e-04 - val_loss: 1.0608e-04\n",
            "Epoch 39/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.6710e-04 - val_loss: 9.0627e-05\n",
            "Epoch 40/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.4161e-04 - val_loss: 3.8445e-04\n",
            "Epoch 41/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.5972e-04 - val_loss: 5.5764e-05\n",
            "Epoch 42/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.4594e-04 - val_loss: 8.9660e-05\n",
            "Epoch 43/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.5490e-04 - val_loss: 1.0378e-04\n",
            "Epoch 44/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 1.4173e-04 - val_loss: 4.6418e-04\n",
            "Epoch 45/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.4757e-04 - val_loss: 1.8410e-04\n",
            "Epoch 46/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.4027e-04 - val_loss: 5.6932e-05\n",
            "Epoch 47/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.4422e-04 - val_loss: 5.0294e-05\n",
            "Epoch 48/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.4399e-04 - val_loss: 5.1389e-05\n",
            "Epoch 49/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.2897e-04 - val_loss: 8.0938e-05\n",
            "Epoch 50/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.3335e-04 - val_loss: 5.2445e-05\n",
            "63/63 [==============================] - 1s 9ms/step\n",
            "model : 2\n",
            "mae 0.8300397374800275\n",
            "mse 1.0789250445007141\n",
            "mape 0.01838390213744286\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 3.7151e-04 - val_loss: 1.6218e-04\n",
            "Epoch 2/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 3.6236e-04 - val_loss: 2.2163e-04\n",
            "Epoch 3/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 3.2756e-04 - val_loss: 3.6013e-04\n",
            "Epoch 4/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 3.1317e-04 - val_loss: 1.0918e-04\n",
            "Epoch 5/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.8407e-04 - val_loss: 1.2137e-04\n",
            "Epoch 6/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 2.8358e-04 - val_loss: 2.0683e-04\n",
            "Epoch 7/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.7958e-04 - val_loss: 1.7726e-04\n",
            "Epoch 8/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 2.5746e-04 - val_loss: 1.2177e-04\n",
            "Epoch 9/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 2.4751e-04 - val_loss: 1.4431e-04\n",
            "Epoch 10/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 2.2490e-04 - val_loss: 1.4236e-04\n",
            "Epoch 11/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 2.0915e-04 - val_loss: 1.7624e-04\n",
            "Epoch 12/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 2.2169e-04 - val_loss: 9.7199e-05\n",
            "Epoch 13/50\n",
            "589/589 [==============================] - 21s 35ms/step - loss: 1.9630e-04 - val_loss: 8.4367e-05\n",
            "Epoch 14/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.8344e-04 - val_loss: 1.4544e-04\n",
            "Epoch 15/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.8617e-04 - val_loss: 6.8141e-05\n",
            "Epoch 16/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.7806e-04 - val_loss: 1.4832e-04\n",
            "Epoch 17/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.6633e-04 - val_loss: 6.9014e-05\n",
            "Epoch 18/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.7121e-04 - val_loss: 8.9666e-05\n",
            "Epoch 19/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.6995e-04 - val_loss: 1.0497e-04\n",
            "Epoch 20/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.6780e-04 - val_loss: 3.4230e-04\n",
            "Epoch 21/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.7127e-04 - val_loss: 6.2811e-05\n",
            "Epoch 22/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.4696e-04 - val_loss: 9.2811e-05\n",
            "Epoch 23/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 1.5427e-04 - val_loss: 3.6796e-04\n",
            "Epoch 24/50\n",
            "589/589 [==============================] - 23s 38ms/step - loss: 1.6165e-04 - val_loss: 6.4329e-05\n",
            "Epoch 25/50\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 1.5280e-04 - val_loss: 9.6026e-05\n",
            "Epoch 26/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.4963e-04 - val_loss: 7.9234e-05\n",
            "Epoch 27/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4340e-04 - val_loss: 3.5096e-04\n",
            "Epoch 28/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.5088e-04 - val_loss: 7.1350e-05\n",
            "Epoch 29/50\n",
            "589/589 [==============================] - 26s 45ms/step - loss: 1.4491e-04 - val_loss: 1.9870e-04\n",
            "Epoch 30/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6200e-04 - val_loss: 1.0458e-04\n",
            "Epoch 31/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.4185e-04 - val_loss: 6.7536e-05\n",
            "Epoch 32/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.4528e-04 - val_loss: 6.0115e-05\n",
            "Epoch 33/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.4727e-04 - val_loss: 6.2622e-05\n",
            "Epoch 34/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.3977e-04 - val_loss: 9.8148e-05\n",
            "Epoch 35/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.3795e-04 - val_loss: 6.5572e-05\n",
            "Epoch 36/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.3498e-04 - val_loss: 2.3141e-04\n",
            "Epoch 37/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.4893e-04 - val_loss: 6.4815e-05\n",
            "Epoch 38/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.3528e-04 - val_loss: 6.9798e-05\n",
            "Epoch 39/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.4026e-04 - val_loss: 1.9453e-04\n",
            "Epoch 40/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.3816e-04 - val_loss: 1.0409e-04\n",
            "Epoch 41/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.3503e-04 - val_loss: 7.7976e-05\n",
            "Epoch 42/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 1.3210e-04 - val_loss: 5.3663e-05\n",
            "Epoch 43/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 1.3088e-04 - val_loss: 8.4938e-05\n",
            "Epoch 44/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 1.3179e-04 - val_loss: 1.0694e-04\n",
            "Epoch 45/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.2826e-04 - val_loss: 7.2698e-05\n",
            "Epoch 46/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.2944e-04 - val_loss: 9.7887e-05\n",
            "Epoch 47/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.3799e-04 - val_loss: 5.4452e-05\n",
            "Epoch 48/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.2972e-04 - val_loss: 5.5837e-05\n",
            "Epoch 49/50\n",
            "589/589 [==============================] - 21s 36ms/step - loss: 1.3314e-04 - val_loss: 1.2090e-04\n",
            "Epoch 50/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.2428e-04 - val_loss: 5.3369e-05\n",
            "63/63 [==============================] - 1s 9ms/step\n",
            "model : 3\n",
            "mae 0.7867111615718357\n",
            "mse 1.0365993741992519\n",
            "mape 0.01655413182592857\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 6.2868e-04 - val_loss: 7.7217e-04\n",
            "Epoch 2/50\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 6.0467e-04 - val_loss: 4.7328e-04\n",
            "Epoch 3/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 5.0228e-04 - val_loss: 5.6802e-04\n",
            "Epoch 4/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 5.2450e-04 - val_loss: 5.9309e-04\n",
            "Epoch 5/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 4.7797e-04 - val_loss: 2.5825e-04\n",
            "Epoch 6/50\n",
            "589/589 [==============================] - 23s 38ms/step - loss: 4.7564e-04 - val_loss: 0.0010\n",
            "Epoch 7/50\n",
            "589/589 [==============================] - 27s 47ms/step - loss: 4.5310e-04 - val_loss: 4.1572e-04\n",
            "Epoch 8/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 4.1802e-04 - val_loss: 1.6850e-04\n",
            "Epoch 9/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 4.2903e-04 - val_loss: 1.4060e-04\n",
            "Epoch 10/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 4.0293e-04 - val_loss: 1.6332e-04\n",
            "Epoch 11/50\n",
            "589/589 [==============================] - 23s 38ms/step - loss: 3.9293e-04 - val_loss: 1.2851e-04\n",
            "Epoch 12/50\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 3.8853e-04 - val_loss: 1.5699e-04\n",
            "Epoch 13/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 3.7177e-04 - val_loss: 1.3042e-04\n",
            "Epoch 14/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 3.5663e-04 - val_loss: 1.2340e-04\n",
            "Epoch 15/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.4538e-04 - val_loss: 2.0020e-04\n",
            "Epoch 16/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 3.4928e-04 - val_loss: 1.3788e-04\n",
            "Epoch 17/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 3.3922e-04 - val_loss: 9.8205e-05\n",
            "Epoch 18/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 3.3553e-04 - val_loss: 1.1284e-04\n",
            "Epoch 19/50\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 3.4436e-04 - val_loss: 8.8563e-05\n",
            "Epoch 20/50\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.3016e-04 - val_loss: 3.0947e-04\n",
            "Epoch 21/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 3.1705e-04 - val_loss: 8.6465e-05\n",
            "Epoch 22/50\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 3.0764e-04 - val_loss: 1.1108e-04\n",
            "Epoch 23/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 3.0699e-04 - val_loss: 1.1072e-04\n",
            "Epoch 24/50\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 2.9427e-04 - val_loss: 0.0010\n",
            "Epoch 25/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 2.9322e-04 - val_loss: 1.2224e-04\n",
            "Epoch 26/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 2.9627e-04 - val_loss: 1.1985e-04\n",
            "Epoch 27/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 2.8951e-04 - val_loss: 1.6704e-04\n",
            "Epoch 28/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 2.9492e-04 - val_loss: 1.2339e-04\n",
            "Epoch 29/50\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 2.7071e-04 - val_loss: 1.2460e-04\n",
            "Epoch 30/50\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 2.6429e-04 - val_loss: 7.5740e-05\n",
            "Epoch 31/50\n",
            "589/589 [==============================] - 23s 38ms/step - loss: 2.5377e-04 - val_loss: 1.0137e-04\n",
            "Epoch 32/50\n",
            "589/589 [==============================] - 26s 43ms/step - loss: 2.3902e-04 - val_loss: 8.8378e-05\n",
            "Epoch 33/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 1.9710e-04 - val_loss: 1.1711e-04\n",
            "Epoch 34/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 2.0090e-04 - val_loss: 1.4598e-04\n",
            "Epoch 35/50\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 1.8251e-04 - val_loss: 9.1160e-05\n",
            "Epoch 36/50\n",
            "589/589 [==============================] - 23s 40ms/step - loss: 1.9765e-04 - val_loss: 5.8950e-05\n",
            "Epoch 37/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 1.7325e-04 - val_loss: 7.7365e-05\n",
            "Epoch 38/50\n",
            "589/589 [==============================] - 26s 43ms/step - loss: 1.7475e-04 - val_loss: 6.1840e-05\n",
            "Epoch 39/50\n",
            "589/589 [==============================] - 23s 38ms/step - loss: 1.8432e-04 - val_loss: 1.3334e-04\n",
            "Epoch 40/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 1.7276e-04 - val_loss: 6.9260e-05\n",
            "Epoch 41/50\n",
            "589/589 [==============================] - 23s 39ms/step - loss: 1.7423e-04 - val_loss: 7.0435e-05\n",
            "Epoch 42/50\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 1.5557e-04 - val_loss: 1.8268e-04\n",
            "Epoch 43/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 1.6284e-04 - val_loss: 4.9984e-05\n",
            "Epoch 44/50\n",
            "589/589 [==============================] - 22s 37ms/step - loss: 1.6348e-04 - val_loss: 9.5759e-05\n",
            "Epoch 45/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 1.4993e-04 - val_loss: 7.0926e-05\n",
            "Epoch 46/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.6070e-04 - val_loss: 6.7500e-05\n",
            "Epoch 47/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 1.4943e-04 - val_loss: 5.5822e-05\n",
            "Epoch 48/50\n",
            "589/589 [==============================] - 26s 45ms/step - loss: 1.4515e-04 - val_loss: 3.7440e-04\n",
            "Epoch 49/50\n",
            "589/589 [==============================] - 22s 38ms/step - loss: 1.5737e-04 - val_loss: 1.1992e-04\n",
            "Epoch 50/50\n",
            "589/589 [==============================] - 25s 43ms/step - loss: 1.5072e-04 - val_loss: 8.6297e-05\n",
            "63/63 [==============================] - 1s 8ms/step\n",
            "model : 4\n",
            "mae 1.1190407758667351\n",
            "mse 1.4049629442056872\n",
            "mape 0.023854870773506696\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "errors of the above models:\n",
        "\n",
        "model : 0\n",
        "\n",
        "mae 1.178879781847908\n",
        "\n",
        "mse 1.4829644867009713\n",
        "\n",
        "mape 0.020081711278341154\n",
        "\n",
        "\n",
        "model : 1\n",
        "\n",
        "mae 0.7788398563861849\n",
        "\n",
        "mse 1.0234463203982023\n",
        "\n",
        "mape 0.017086112517337756\n",
        "\n",
        "\n",
        "model : 2\n",
        "\n",
        "mae 0.8300397374800275\n",
        "\n",
        "mse 1.0789250445007141\n",
        "\n",
        "mape 0.01838390213744286\n",
        "\n",
        "model : 3\n",
        "\n",
        "mae 0.7867111615718357\n",
        "\n",
        "mse 1.0365993741992519\n",
        "\n",
        "mape 0.01655413182592857\n",
        "\n",
        "model : 4\n",
        "\n",
        "mae 1.1190407758667351\n",
        "\n",
        "mse 1.4049629442056872\n",
        "\n",
        "mape 0.023854870773506696"
      ],
      "metadata": {
        "id": "T3mkUz50rOf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models[1].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJHnWXScv2nZ",
        "outputId": "b789a6bb-5151-465c-ce1d-6c6a7e74072b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input1 (InputLayer)            [(None, 15, 4)]      0           []                               \n",
            "                                                                                                  \n",
            " separable_conv1d_50 (Separable  (None, 13, 21)      117         ['input1[0][0]']                 \n",
            " Conv1D)                                                                                          \n",
            "                                                                                                  \n",
            " separable_conv1d_51 (Separable  (None, 11, 14)      371         ['separable_conv1d_50[0][0]']    \n",
            " Conv1D)                                                                                          \n",
            "                                                                                                  \n",
            " separable_conv1d_52 (Separable  (None, 9, 14)       252         ['separable_conv1d_51[0][0]']    \n",
            " Conv1D)                                                                                          \n",
            "                                                                                                  \n",
            " flatten_12 (Flatten)           (None, 126)          0           ['separable_conv1d_52[0][0]']    \n",
            "                                                                                                  \n",
            " repeat_vector_12 (RepeatVector  (None, 1, 126)      0           ['flatten_12[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " input2 (InputLayer)            [(None, 15, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " input3 (InputLayer)            [(None, 15, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_34 (LSTM)                 (None, 35)           22680       ['repeat_vector_12[0][0]']       \n",
            "                                                                                                  \n",
            " bidirectional_24 (Bidirectiona  (None, 56)          6720        ['input2[0][0]']                 \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " bidirectional_25 (Bidirectiona  (None, 56)          6720        ['input3[0][0]']                 \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 147)          0           ['lstm_34[0][0]',                \n",
            "                                                                  'bidirectional_24[0][0]',       \n",
            "                                                                  'bidirectional_25[0][0]']       \n",
            "                                                                                                  \n",
            " dense_30 (Dense)               (None, 14)           2072        ['concatenate_12[0][0]']         \n",
            "                                                                                                  \n",
            " dense_31 (Dense)               (None, 7)            105         ['dense_30[0][0]']               \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 1)            8           ['dense_31[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 39,045\n",
            "Trainable params: 39,045\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QP5ONNZmv2tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uo1ZvN78v2wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4NbO9fIv2yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Usv9_Xnov21n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "p3zMeb9K91ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv3KNvxc4FiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caed1ad1-8c83-4391-be79-4483544273fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140464"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# tf lite model with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"conv_lstm_nasdq_quant.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_modelq = tf.lite.Interpreter(\"conv_lstm_nasdq_quant.tflite\")\n",
        "tf_modelq.allocate_tensors()\n",
        "input_details = tf_modelq.get_input_details()\n",
        "output_details = tf_modelq.get_output_details()\n",
        "tf_modelq_predictions = []\n",
        "input_shape = input_details[0]['shape']\n",
        "input_shape1 = input_details[1]['shape']\n",
        "input_shape2 = input_details[2]['shape']\n",
        "input_data = np.array(test_x, dtype=np.float32)\n",
        "input_data1 = np.array(test_x_w, dtype=np.float32)\n",
        "input_data2 = np.array(test_x_d, dtype=np.float32)\n",
        "tf_model_output_index = output_details[0]['index']\n",
        "for i in range(len(test_x)):\n",
        "    tf_modelq.set_tensor(input_details[0]['index'], input_data2[i].reshape(1,input_data2.shape[1],1))\n",
        "    tf_modelq.set_tensor(input_details[1]['index'], input_data[i].reshape(1,input_data.shape[1],input_data.shape[2]))\n",
        "    tf_modelq.set_tensor(input_details[2]['index'], input_data1[i].reshape(1,input_data1.shape[1],1))\n",
        "    tf_modelq.invoke()\n",
        "    x1=tf_modelq.get_tensor(tf_model_output_index)\n",
        "    tf_modelq_predictions.append(x1[0])"
      ],
      "metadata": {
        "id": "mQ6NiXrp93OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_pred=scaler1.inverse_transform(tf_modelq_predictions)"
      ],
      "metadata": {
        "id": "ZFMlkvw--IVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(mae(tf_pred,test_Y))"
      ],
      "metadata": {
        "id": "iEb5CZGb-QEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f80aae-d3ad-4a6b-b031-130c6f1c3dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9674679904433328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sqrt(mse(tf_pred,test_Y)))"
      ],
      "metadata": {
        "id": "UbZnf1P7-Rvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31c4e42-76b5-4985-981c-09a2457f6443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.427730179966212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mape(tf_pred,test_Y))"
      ],
      "metadata": {
        "id": "VcV3qhr0-TYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e93734-58e0-4fcf-f753-af7f6dea8428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03735375076066441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QVPn_EQ2-1gM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}