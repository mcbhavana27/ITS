{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcbhavana27/ITS/blob/main/CNN_LSTM_depthwise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmgxsJYg7ri-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "from keras.models import Sequential,Model\n",
        "from keras.metrics import MeanSquaredError as mae\n",
        "from keras.layers import LSTM,Dense,Dropout,Conv1D,TimeDistributed,Input,Flatten,Concatenate\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
        "from math import sqrt\n",
        "#from bokeh.plotting import figure,output_file, show\n",
        "import datetime\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "#from openpyxl import Workbook,load_workbook\n",
        "from keras.layers import DepthwiseConv2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS6_yN0_7y4H",
        "outputId": "eec1cffa-3e02-4ebf-d37c-ec7231caa129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  /content/drive/My\\ Drive/DATA.zip /content/\n",
        "!unzip DATA.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1BMqZ3Q9tE3",
        "outputId": "4d39d149-f2cb-4fd7-da86-4acc18d48b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  DATA.zip\n",
            "   creating: DATA/\n",
            "   creating: DATA/402214/\n",
            "  inflating: DATA/402214/8.csv       \n",
            "  inflating: DATA/402214/9.csv       \n",
            "  inflating: DATA/402214/1.csv       \n",
            "  inflating: DATA/402214/2.csv       \n",
            "  inflating: DATA/402214/5.csv       \n",
            "  inflating: DATA/402214/4.csv       \n",
            "  inflating: DATA/402214/11.csv      \n",
            "  inflating: DATA/402214/3.csv       \n",
            "  inflating: DATA/402214/10.csv      \n",
            "  inflating: DATA/402214/12.csv      \n",
            "  inflating: DATA/402214/13.csv      \n",
            "  inflating: DATA/402214/7.csv       \n",
            "  inflating: DATA/402214/6.csv       \n",
            "   creating: DATA/402510/\n",
            "  inflating: DATA/402510/3.csv       \n",
            "  inflating: DATA/402510/12.csv      \n",
            "  inflating: DATA/402510/13.csv      \n",
            "  inflating: DATA/402510/10.csv      \n",
            "  inflating: DATA/402510/8.csv       \n",
            "  inflating: DATA/402510/4.csv       \n",
            "  inflating: DATA/402510/11.csv      \n",
            "  inflating: DATA/402510/7.csv       \n",
            "  inflating: DATA/402510/6.csv       \n",
            "  inflating: DATA/402510/9.csv       \n",
            "  inflating: DATA/402510/5.csv       \n",
            "  inflating: DATA/402510/1.csv       \n",
            "  inflating: DATA/402510/2.csv       \n",
            "   creating: DATA/402835/\n",
            "  inflating: DATA/402835/10.csv      \n",
            "  inflating: DATA/402835/1.csv       \n",
            "  inflating: DATA/402835/7.csv       \n",
            "  inflating: DATA/402835/12.csv      \n",
            "  inflating: DATA/402835/13.csv      \n",
            "  inflating: DATA/402835/11.csv      \n",
            "  inflating: DATA/402835/2.csv       \n",
            "  inflating: DATA/402835/9.csv       \n",
            "  inflating: DATA/402835/4.csv       \n",
            "  inflating: DATA/402835/6.csv       \n",
            "  inflating: DATA/402835/5.csv       \n",
            "  inflating: DATA/402835/8.csv       \n",
            "  inflating: DATA/402835/3.csv       \n",
            "   creating: DATA/414025/\n",
            "  inflating: DATA/414025/10.csv      \n",
            "  inflating: DATA/414025/8.csv       \n",
            "  inflating: DATA/414025/12.csv      \n",
            "  inflating: DATA/414025/7.csv       \n",
            "  inflating: DATA/414025/3.csv       \n",
            "  inflating: DATA/414025/5.csv       \n",
            "  inflating: DATA/414025/13.csv      \n",
            "  inflating: DATA/414025/11.csv      \n",
            "  inflating: DATA/414025/2.csv       \n",
            "  inflating: DATA/414025/4.csv       \n",
            "  inflating: DATA/414025/6.csv       \n",
            "  inflating: DATA/414025/1.csv       \n",
            "  inflating: DATA/414025/9.csv       \n",
            "  inflating: DATA/pems_output4.csv   \n",
            "  inflating: DATA/pems_output5.csv   \n",
            "  inflating: DATA/pems_output6.csv   \n",
            "  inflating: DATA/pems_output7.csv   \n",
            "   creating: DATA/402212/\n",
            "  inflating: DATA/402212/10.csv      \n",
            "  inflating: DATA/402212/1.csv       \n",
            "  inflating: DATA/402212/6.csv       \n",
            "  inflating: DATA/402212/12.csv      \n",
            "  inflating: DATA/402212/2.csv       \n",
            "  inflating: DATA/402212/9.csv       \n",
            "  inflating: DATA/402212/3.csv       \n",
            "  inflating: DATA/402212/8.csv       \n",
            "  inflating: DATA/402212/11.csv      \n",
            "  inflating: DATA/402212/4.csv       \n",
            "  inflating: DATA/402212/13.csv      \n",
            "  inflating: DATA/402212/7.csv       \n",
            "  inflating: DATA/402212/5.csv       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed346joN7rjG"
      },
      "outputs": [],
      "source": [
        "Data_file1= glob('DATA/402214'+'/*.csv')\n",
        "Data_file2= glob('DATA/402510'+'/*.csv')\n",
        "Data_file3= glob('DATA/402835'+'/*.csv')\n",
        "Data_file4= glob('DATA/414025'+'/*.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFC1709p7rjH"
      },
      "outputs": [],
      "source": [
        "def data(files,col):\n",
        "    data=[]\n",
        "    for file in files:\n",
        "          data.append(pd.read_csv(file))\n",
        "    full_data =pd.concat(data,ignore_index=True)\n",
        "    cols=list(full_data)[col]\n",
        "    data_set=full_data[cols].astype(str)\n",
        "    data_set = np.array(data_set)\n",
        "    return data_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqhWh4o77rjJ"
      },
      "outputs": [],
      "source": [
        "Data1 = data(Data_file1,2)\n",
        "Data2 = data(Data_file2,2)\n",
        "Data3 = data(Data_file3,2)\n",
        "Data4 = data(Data_file4,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7WPJ2yn7rjJ"
      },
      "outputs": [],
      "source": [
        "data1 = Data1.reshape(Data1.shape[0],1)\n",
        "scaler1 =MinMaxScaler(feature_range=(0, 1))\n",
        "data1_scaled = scaler1.fit_transform(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX1BD7I57rjL"
      },
      "outputs": [],
      "source": [
        "data_set = ([Data1,Data2,Data3,Data4])\n",
        "max_len =max([len(data) for data in data_set ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPAIJQUc7rjL"
      },
      "outputs": [],
      "source": [
        "def fill_data(data):\n",
        "    x=data\n",
        "    l=len(x)\n",
        "    y=x\n",
        "    while l<max_len:\n",
        "        y= np.insert(x,-1,x[-1])\n",
        "        x=y\n",
        "        l=len(x)\n",
        "    return y\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPV5HVDN7rjN"
      },
      "outputs": [],
      "source": [
        "data1 =fill_data(Data1)\n",
        "data2 = fill_data(Data2)\n",
        "data3 = fill_data(Data3)\n",
        "data4 = fill_data(Data4)\n",
        "data_set = np.column_stack((data1,data2,data3,data4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huKhPA6D7rjO"
      },
      "outputs": [],
      "source": [
        "scaler =MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ukw0Nra7rjP"
      },
      "outputs": [],
      "source": [
        "n_step = 21\n",
        "Data =[]\n",
        "\n",
        "for i in range(max_len-(n_step+1)):\n",
        "    Data.append(data_scaled[i:i+n_step+1])\n",
        "\n",
        "Data =np.array(Data)\n",
        "#Data = Data.reshape(Data.shape[0],Data.shape[2],Data.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bn-5xQM7rjR"
      },
      "outputs": [],
      "source": [
        "Train = Data[:]\n",
        "Train_Y=Train[:,-1,0]\n",
        "Train_X = Train[:,:n_step]\n",
        "Train_X1 =Train[:,:n_step,0]\n",
        "Train_wd =Train[:,:n_step]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgXzyb997rjS"
      },
      "outputs": [],
      "source": [
        "x=[]\n",
        "x1=[]\n",
        "x_w=[]\n",
        "x_d=[]\n",
        "y=[]\n",
        "for i in range(len(Train)):\n",
        "    if i >= 2016:\n",
        "        x.append(Train_X[i])\n",
        "        x_w.append(Train_X[i-2016])\n",
        "        x_d.append(Train_X[i-288])\n",
        "        x1.append(Train_X1[i])\n",
        "        y.append(Train_Y[i])\n",
        "x=np.array(x)\n",
        "x1=np.array(x1)\n",
        "x_w=np.array(x_w)\n",
        "x_d=np.array(x_d)\n",
        "y=np.array(y)      \n",
        "y=y.reshape(y.shape[0],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akdMujFZ7rjS",
        "outputId": "63d203e0-ef34-4765-ea68-9b26cd54f750"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24155, 21), (24155, 21, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x1.shape,x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xgm09UY7rjU"
      },
      "outputs": [],
      "source": [
        "train_x=x[:-2016]\n",
        "test_x=x[-2016:]\n",
        "train_x1=x1[:-2016]\n",
        "test_x1=x1[-2016:]\n",
        "train_x_w=x_w[:-2016]\n",
        "test_x_w=x_w[-2016:]\n",
        "train_x_d=x_d[:-2016]\n",
        "test_x_d=x_d[-2016:]\n",
        "train_y=y[:-2016]\n",
        "test_y=y[-2016:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ncpnNeB7rjW"
      },
      "outputs": [],
      "source": [
        "train_x1=train_x1.reshape(train_x1.shape[0],train_x1.shape[1],1)\n",
        "test_x1=test_x1.reshape(test_x1.shape[0],test_x1.shape[1],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no5_8jwd7rjW"
      },
      "outputs": [],
      "source": [
        "input1=Input(shape=(n_step,4),name ='input1')\n",
        "input2=Input(shape=(n_step,1),name ='input2')\n",
        "input3=Input(shape=(n_step,4),name ='input3')\n",
        "input4=Input(shape=(n_step,4),name ='input4')\n",
        "\n",
        "# Original 1D convolutional layer\n",
        "# conv1d_layer1 = tf.keras.layers.Conv1D(filters=30, kernel_size=3, strides=1, padding='same', activation='relu')\n",
        "\n",
        "\n",
        "# Original 1D convolutional layer\n",
        "# conv1d_layer2 = tf.keras.layers.Conv1D(filters=30, kernel_size=3, strides=1, padding='same', activation='relu')\n",
        "\n",
        "# Original 1D convolutional layer\n",
        "# conv1d_layer3 = tf.keras.layers.Conv1D(filters=20, kernel_size=2, strides=1, padding='same', activation='relu')\n",
        "\n",
        "\n",
        "con1=tf.keras.layers.DepthwiseConv1D(30,3,padding='same',activation='relu',name='con1')(input1)\n",
        "# Depthwise separable version of the 1D convolutional layer\n",
        "# depthwise_conv1d_layer1 = tf.keras.layers.DepthwiseConv1D(kernel_size=3, strides=1, padding='same', activation='relu')\n",
        "# separable_conv1d_layer1 = tf.keras.layers.SeparableConv1D(filters=30, kernel_size=1, strides=1, padding='same', activation='relu')\n",
        "\n",
        "con2=tf.keras.layers.DepthwiseConv1D(30,3,padding='same',activation='relu',name='con2')(con1)\n",
        "\n",
        "# Depthwise separable version of the 1D convolutional layer\n",
        "# depthwise_conv1d_layer2 = tf.keras.layers.DepthwiseConv1D(kernel_size=3, strides=1, padding='same', activation='relu')\n",
        "# separable_conv1d_layer2 = tf.keras.layers.SeparableConv1D(filters=30, kernel_size=1, strides=1, padding='same', activation='relu')\n",
        "\n",
        "con3=tf.keras.layers.DepthwiseConv1D(20,2,padding='same',activation='relu',name='con3')(con2)\n",
        "# Depthwise separable version of the 1D convolutional layer\n",
        "# depthwise_conv1d_layer3 = tf.keras.layers.DepthwiseConv1D(kernel_size=2, strides=1, padding='same', activation='relu')\n",
        "# separable_conv1d_layer3 = tf.keras.layers.SeparableConv1D(filters=20, kernel_size=1, strides=1, padding='same', activation='relu')\n",
        "\n",
        "con_fl = Flatten()(con3)\n",
        "\n",
        "# # Stack the depthwise separable layers\n",
        "# model = tf.keras.Sequential([\n",
        "#   depthwise_conv1d_layer1,\n",
        "#   separable_conv1d_layer1\n",
        "# ])\n",
        "\n",
        "lstm_out=LSTM(60,activation='relu',return_sequences=False,name='lstm_out')(input2)\n",
        "lstm_out1=LSTM(30,activation='relu',return_sequences=True,name='lstm_out1')(input3)\n",
        "lstm_out2=LSTM(30,activation='relu',return_sequences=False,name='lstm_out2')(lstm_out1)\n",
        "lstm_out3=LSTM(30,activation='relu',return_sequences=True,name='lstm_out3')(input4)\n",
        "lstm_out4=LSTM(30,activation='relu',return_sequences=False,name='lstm_out4')(lstm_out3)\n",
        "x=Concatenate()([con_fl,lstm_out,lstm_out2,lstm_out4])\n",
        "x1=Dense(20,activation='relu',name='x1')(x)\n",
        "x2=Dense(10,activation='relu',name='x2')(x1)\n",
        "output1 = Dense(1,activation='relu',kernel_regularizer=regularizers.l1(0.002),name='output1')(x2)\n",
        "model=Model(inputs=[input1,input2,input3,input4],outputs=output1)\n",
        "model.compile(optimizer='adam',loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KVuG8oo7rjX",
        "outputId": "62d2f49b-0164-4d59-9a15-feb14353db73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "589/589 [==============================] - 31s 43ms/step - loss: 0.4178 - val_loss: 0.4221\n",
            "Epoch 2/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 0.0984 - val_loss: 0.0010\n",
            "Epoch 3/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 4/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 8.1186e-04 - val_loss: 6.7102e-04\n",
            "Epoch 5/100\n",
            "589/589 [==============================] - 42s 72ms/step - loss: 7.1360e-04 - val_loss: 5.9846e-04\n",
            "Epoch 6/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 6.6148e-04 - val_loss: 5.3074e-04\n",
            "Epoch 7/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 5.8556e-04 - val_loss: 0.0013\n",
            "Epoch 8/100\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 5.6512e-04 - val_loss: 4.3684e-04\n",
            "Epoch 9/100\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 5.1248e-04 - val_loss: 4.5705e-04\n",
            "Epoch 10/100\n",
            "589/589 [==============================] - 27s 46ms/step - loss: 4.8656e-04 - val_loss: 6.4381e-04\n",
            "Epoch 11/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 4.5038e-04 - val_loss: 3.9393e-04\n",
            "Epoch 12/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 4.2620e-04 - val_loss: 0.0015\n",
            "Epoch 13/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 4.0923e-04 - val_loss: 3.2545e-04\n",
            "Epoch 14/100\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 4.1049e-04 - val_loss: 3.0562e-04\n",
            "Epoch 15/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.6138e-04 - val_loss: 7.8332e-04\n",
            "Epoch 16/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.5553e-04 - val_loss: 3.6024e-04\n",
            "Epoch 17/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.3154e-04 - val_loss: 0.0042\n",
            "Epoch 18/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 5.8454e-04 - val_loss: 5.0003e-04\n",
            "Epoch 19/100\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 4.0924e-04 - val_loss: 3.3209e-04\n",
            "Epoch 20/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.9141e-04 - val_loss: 2.8945e-04\n",
            "Epoch 21/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.6281e-04 - val_loss: 2.9867e-04\n",
            "Epoch 22/100\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 3.4775e-04 - val_loss: 3.5642e-04\n",
            "Epoch 23/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.1166e-04 - val_loss: 2.5744e-04\n",
            "Epoch 24/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 3.0608e-04 - val_loss: 2.7826e-04\n",
            "Epoch 25/100\n",
            "589/589 [==============================] - 29s 48ms/step - loss: 2.8202e-04 - val_loss: 3.2706e-04\n",
            "Epoch 26/100\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 2.6524e-04 - val_loss: 2.4184e-04\n",
            "Epoch 27/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.5625e-04 - val_loss: 3.5134e-04\n",
            "Epoch 28/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.4430e-04 - val_loss: 3.0690e-04\n",
            "Epoch 29/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.2870e-04 - val_loss: 1.8184e-04\n",
            "Epoch 30/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.2249e-04 - val_loss: 3.1461e-04\n",
            "Epoch 31/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.3017e-04 - val_loss: 1.5862e-04\n",
            "Epoch 32/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.1634e-04 - val_loss: 1.7212e-04\n",
            "Epoch 33/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.1041e-04 - val_loss: 4.5547e-04\n",
            "Epoch 34/100\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 2.2039e-04 - val_loss: 2.7359e-04\n",
            "Epoch 35/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.0190e-04 - val_loss: 3.9380e-04\n",
            "Epoch 36/100\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.8841e-04 - val_loss: 1.3953e-04\n",
            "Epoch 37/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.9228e-04 - val_loss: 1.2908e-04\n",
            "Epoch 38/100\n",
            "589/589 [==============================] - 32s 55ms/step - loss: 2.1205e-04 - val_loss: 1.3353e-04\n",
            "Epoch 39/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.7970e-04 - val_loss: 1.4476e-04\n",
            "Epoch 40/100\n",
            "589/589 [==============================] - 29s 49ms/step - loss: 1.9155e-04 - val_loss: 2.3056e-04\n",
            "Epoch 41/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 2.0583e-04 - val_loss: 2.3106e-04\n",
            "Epoch 42/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.8954e-04 - val_loss: 1.3156e-04\n",
            "Epoch 43/100\n",
            "589/589 [==============================] - 28s 48ms/step - loss: 1.7999e-04 - val_loss: 2.0964e-04\n",
            "Epoch 44/100\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 1.8488e-04 - val_loss: 1.2882e-04\n",
            "Epoch 45/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.8805e-04 - val_loss: 1.2414e-04\n",
            "Epoch 46/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.7445e-04 - val_loss: 1.2982e-04\n",
            "Epoch 47/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.7682e-04 - val_loss: 1.2279e-04\n",
            "Epoch 48/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.7267e-04 - val_loss: 1.3882e-04\n",
            "Epoch 49/100\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.7318e-04 - val_loss: 1.1730e-04\n",
            "Epoch 50/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.7266e-04 - val_loss: 2.1505e-04\n",
            "Epoch 51/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.8397e-04 - val_loss: 1.8985e-04\n",
            "Epoch 52/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6905e-04 - val_loss: 1.3451e-04\n",
            "Epoch 53/100\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 1.7246e-04 - val_loss: 1.5254e-04\n",
            "Epoch 54/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6809e-04 - val_loss: 1.3491e-04\n",
            "Epoch 55/100\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 1.7233e-04 - val_loss: 1.1947e-04\n",
            "Epoch 56/100\n",
            "589/589 [==============================] - 28s 48ms/step - loss: 1.6004e-04 - val_loss: 2.2895e-04\n",
            "Epoch 57/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6840e-04 - val_loss: 1.7107e-04\n",
            "Epoch 58/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6907e-04 - val_loss: 1.2285e-04\n",
            "Epoch 59/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5676e-04 - val_loss: 1.2952e-04\n",
            "Epoch 60/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5906e-04 - val_loss: 1.6848e-04\n",
            "Epoch 61/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5912e-04 - val_loss: 1.1690e-04\n",
            "Epoch 62/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6235e-04 - val_loss: 1.4555e-04\n",
            "Epoch 63/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5879e-04 - val_loss: 2.1380e-04\n",
            "Epoch 64/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6280e-04 - val_loss: 1.1760e-04\n",
            "Epoch 65/100\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 1.5765e-04 - val_loss: 1.0765e-04\n",
            "Epoch 66/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6251e-04 - val_loss: 1.0287e-04\n",
            "Epoch 67/100\n",
            "589/589 [==============================] - 24s 40ms/step - loss: 1.5368e-04 - val_loss: 1.1986e-04\n",
            "Epoch 68/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5400e-04 - val_loss: 9.9029e-05\n",
            "Epoch 69/100\n",
            "589/589 [==============================] - 29s 49ms/step - loss: 1.5821e-04 - val_loss: 1.0613e-04\n",
            "Epoch 70/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4638e-04 - val_loss: 1.1208e-04\n",
            "Epoch 71/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5220e-04 - val_loss: 1.0799e-04\n",
            "Epoch 72/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5360e-04 - val_loss: 1.1258e-04\n",
            "Epoch 73/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4845e-04 - val_loss: 1.0554e-04\n",
            "Epoch 74/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.6229e-04 - val_loss: 1.1978e-04\n",
            "Epoch 75/100\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 1.4936e-04 - val_loss: 9.6791e-05\n",
            "Epoch 76/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.3962e-04 - val_loss: 9.5956e-05\n",
            "Epoch 77/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5901e-04 - val_loss: 9.8537e-05\n",
            "Epoch 78/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.7781e-04 - val_loss: 1.1121e-04\n",
            "Epoch 79/100\n",
            "589/589 [==============================] - 25s 42ms/step - loss: 1.4673e-04 - val_loss: 1.5394e-04\n",
            "Epoch 80/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4763e-04 - val_loss: 1.0940e-04\n",
            "Epoch 81/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5483e-04 - val_loss: 1.0179e-04\n",
            "Epoch 82/100\n",
            "589/589 [==============================] - 27s 45ms/step - loss: 1.4684e-04 - val_loss: 1.0340e-04\n",
            "Epoch 83/100\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 1.5187e-04 - val_loss: 9.8830e-05\n",
            "Epoch 84/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4567e-04 - val_loss: 9.6373e-05\n",
            "Epoch 85/100\n",
            "589/589 [==============================] - 26s 45ms/step - loss: 1.5007e-04 - val_loss: 1.6660e-04\n",
            "Epoch 86/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4478e-04 - val_loss: 1.8839e-04\n",
            "Epoch 87/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5159e-04 - val_loss: 1.6117e-04\n",
            "Epoch 88/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4462e-04 - val_loss: 1.5730e-04\n",
            "Epoch 89/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4693e-04 - val_loss: 1.1874e-04\n",
            "Epoch 90/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5597e-04 - val_loss: 9.4144e-05\n",
            "Epoch 91/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4067e-04 - val_loss: 1.3116e-04\n",
            "Epoch 92/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4150e-04 - val_loss: 3.1743e-04\n",
            "Epoch 93/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.5067e-04 - val_loss: 1.0519e-04\n",
            "Epoch 94/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4487e-04 - val_loss: 1.0788e-04\n",
            "Epoch 95/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4696e-04 - val_loss: 1.1903e-04\n",
            "Epoch 96/100\n",
            "589/589 [==============================] - 26s 44ms/step - loss: 1.4181e-04 - val_loss: 9.2396e-05\n",
            "Epoch 97/100\n",
            "589/589 [==============================] - 28s 48ms/step - loss: 1.4082e-04 - val_loss: 1.2480e-04\n",
            "Epoch 98/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4474e-04 - val_loss: 9.7021e-05\n",
            "Epoch 99/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4045e-04 - val_loss: 9.1265e-05\n",
            "Epoch 100/100\n",
            "589/589 [==============================] - 24s 41ms/step - loss: 1.4298e-04 - val_loss: 1.9722e-04\n"
          ]
        }
      ],
      "source": [
        "history=model.fit([train_x,train_x1,train_x_w,train_x_d],train_y,epochs=100,validation_split=.15,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3-zIRJR7rjX",
        "outputId": "5179d774-6adb-46e4-dc31-c645bd444d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input1 (InputLayer)            [(None, 21, 4)]      0           []                               \n",
            "                                                                                                  \n",
            " con1 (DepthwiseConv1D)         (None, 7, 4)         124         ['input1[0][0]']                 \n",
            "                                                                                                  \n",
            " con2 (DepthwiseConv1D)         (None, 3, 4)         124         ['con1[0][0]']                   \n",
            "                                                                                                  \n",
            " input3 (InputLayer)            [(None, 21, 4)]      0           []                               \n",
            "                                                                                                  \n",
            " input4 (InputLayer)            [(None, 21, 4)]      0           []                               \n",
            "                                                                                                  \n",
            " con3 (DepthwiseConv1D)         (None, 2, 4)         84          ['con2[0][0]']                   \n",
            "                                                                                                  \n",
            " input2 (InputLayer)            [(None, 21, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_out1 (LSTM)               (None, 21, 30)       4200        ['input3[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_out3 (LSTM)               (None, 21, 30)       4200        ['input4[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 8)            0           ['con3[0][0]']                   \n",
            "                                                                                                  \n",
            " lstm_out (LSTM)                (None, 60)           14880       ['input2[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_out2 (LSTM)               (None, 30)           7320        ['lstm_out1[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_out4 (LSTM)               (None, 30)           7320        ['lstm_out3[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128)          0           ['flatten[0][0]',                \n",
            "                                                                  'lstm_out[0][0]',               \n",
            "                                                                  'lstm_out2[0][0]',              \n",
            "                                                                  'lstm_out4[0][0]']              \n",
            "                                                                                                  \n",
            " x1 (Dense)                     (None, 20)           2580        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " x2 (Dense)                     (None, 10)           210         ['x1[0][0]']                     \n",
            "                                                                                                  \n",
            " output1 (Dense)                (None, 1)            11          ['x2[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 41,053\n",
            "Trainable params: 41,053\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2B2YD4Ac7rjY",
        "outputId": "e8e3a3f6-8ce2-4cb2-dcd6-9a5304a49125"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history[\"loss\"],color='green')\n",
        "plt.plot(history.history[\"val_loss\"],color='blue')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLkIy31D7rjZ",
        "outputId": "79002313-5850-4913-f16e-80d6e8fb4814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "y_predict_scaled = model.predict([test_x,test_x1,test_x_w,test_x_d])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RewUMwj17rjZ"
      },
      "outputs": [],
      "source": [
        "y_predict=scaler1.inverse_transform(y_predict_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmE6W9uQ7rja"
      },
      "outputs": [],
      "source": [
        "test_Y=scaler1.inverse_transform(test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76xg4aY7rjb",
        "outputId": "f1b8ee98-b5b9-4d2e-ce35-4c6ea3df7ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.231132375815558\n"
          ]
        }
      ],
      "source": [
        "print(mae(y_predict,test_Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEa9e55G7rjb",
        "outputId": "b0f29779-24ec-44b3-8f94-a17ebd21df5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.391439123644025\n"
          ]
        }
      ],
      "source": [
        "print(sqrt(mse(y_predict,test_Y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UcHAnJy7rjc",
        "outputId": "c31b6e85-d900-482c-da09-a04e03ff1888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1044703642688132\n"
          ]
        }
      ],
      "source": [
        "print(mape(y_predict,test_Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJDqYp4B7rjd"
      },
      "outputs": [],
      "source": [
        "Error=[]\n",
        "for i in range(len(test_Y)):\n",
        "    Error.append(abs(y_predict[i]-test_Y[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuYrT83s7rjd",
        "outputId": "66ff5ef1-55aa-416b-c2e9-6a19125881b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92616"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# tf lite model with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "\n",
        "\n",
        "# def representative_dataset_generator():\n",
        "#   for value in X_test:\n",
        "#     # Each scalar value must be inside of a 2D array that is wrapped in a list\n",
        "#     print(value)\n",
        "#     yield [np.array(value, dtype=np.float32, ndmin=2)]\n",
        "# converter.representative_dataset = representative_dataset_generator\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"cnn_lstm_model_quantized.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XIL612l7rjd"
      },
      "outputs": [],
      "source": [
        "\n",
        "tf_modelq = tf.lite.Interpreter('cnn_lstm_model_quantized.tflite')\n",
        "tf_modelq.allocate_tensors()\n",
        "input_details = tf_modelq.get_input_details()\n",
        "output_details = tf_modelq.get_output_details()\n",
        "tf_modelq_predictions = []\n",
        "input_shape = input_details[0]['shape']\n",
        "input_shape1 = input_details[1]['shape']\n",
        "input_shape2 = input_details[2]['shape']\n",
        "input_shape3 = input_details[3]['shape']\n",
        "input_data = np.array(test_x, dtype=np.float32)\n",
        "input_data1 = np.array(test_x1, dtype=np.float32)\n",
        "input_data2 = np.array(test_x_w, dtype=np.float32)\n",
        "input_data3 = np.array(test_x_d, dtype=np.float32)\n",
        "tf_model_output_index = output_details[0]['index']\n",
        "for i in range(len(test_x1)):\n",
        "    tf_modelq.set_tensor(input_details[0]['index'], input_data2[i].reshape(1,input_data2.shape[1],input_data2.shape[2]))\n",
        "    tf_modelq.set_tensor(input_details[1]['index'], input_data[i].reshape(1,input_data.shape[1],input_data.shape[2]))\n",
        "    tf_modelq.set_tensor(input_details[2]['index'], input_data3[i].reshape(1,input_data3.shape[1],input_data3.shape[2]))\n",
        "    tf_modelq.set_tensor(input_details[3]['index'], input_data1[i].reshape(1,input_data1.shape[1],input_data1.shape[2]))\n",
        "    \n",
        "    tf_modelq.invoke()\n",
        "    x1=tf_modelq.get_tensor(tf_model_output_index)\n",
        "    tf_modelq_predictions.append(x1[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_pred=scaler1.inverse_transform(tf_modelq_predictions)"
      ],
      "metadata": {
        "id": "WJLodVhWuNJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mae(tf_pred,test_Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZSLTNANu_gl",
        "outputId": "ee22cc5b-f2f0-4d57-f11b-f6a915525250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.218364389430332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sqrt(mse(tf_pred,test_Y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP64CpfHvDw7",
        "outputId": "72593503-8339-49ef-dc63-f21113f7cd9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.370306762181542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mape(tf_pred,test_Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzeLZdeevE1J",
        "outputId": "1898b01d-e19e-4617-9abc-a4b2796885ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10468556565437277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wqncUvXRvFCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GtblpjLrvFEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "riQgSFGyvFJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Spe0ZzuZvFLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}